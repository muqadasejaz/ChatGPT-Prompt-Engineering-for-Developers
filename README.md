# ğŸ§  ChatGPT Prompt Engineering for Developers

I recently practiced the **ChatGPT Prompt Engineering for Developers** course by [DeepLearning.AI](https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/) and wanted to share my learning journey.  
This repository contains my notes, experiments, and insights on **effective prompt engineering** for large language models like GPT-3.5.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸš€ What I Learned

This project focuses on two key **Prompting Principles** and related **Tactics** to write better, more reliable prompts.

### ğŸ§© Principle 1: Write Clear and Specific Instructions
- **Tactic 1:** Use delimiters (like triple backticks or quotes) to clearly separate parts of the input.  
- **Tactic 2:** Request structured outputs such as JSON or HTML to organize results.  
- **Tactic 3:** Ask the model to verify whether conditions or instructions are satisfied.  
- **Tactic 4:** Use few-shot prompting by providing examples to guide style and tone.

### ğŸ§  Principle 2: Give the Model Time to â€œThinkâ€
- **Tactic 1:** Specify clear steps to complete a task.  
- **Tactic 2:** Ask the model to reason step-by-step before producing a final answer.

By applying these principles, you can guide the model toward more **accurate, consistent, and relevant outputs**.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ§ª Experiments and Examples

In my notebook, I experimented with:
- Writing clear and specific prompts
- Generating structured outputs like JSON
- Checking conditions and verifying sequences
- Few-shot prompting to maintain style consistency
- Step-by-step reasoning for complex tasks
- Exploring model limitations and hallucinations

These examples helped me understand how to **control the modelâ€™s behavior** and get better results.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## âš ï¸ Model Limitations

Even with carefully crafted prompts, models can sometimes **hallucinate**,  that is, generate plausible but incorrect information.  
Prompt engineering can reduce errors, but it cannot fully eliminate hallucinations.  
Being aware of these limitations is crucial when using LLMs for real applications.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ“š Resources & Credits

This notebook is inspired by the [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/) course by **Andrew Ng** and **Isa Fulford** at **DeepLearning.AI**.  
All concepts and examples are adapted for **practice and learning purposes**.


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ‘¤ Author

Muqadas Ejaz

BS Computer Science (AI Specialization)

AI/ML Engineer

Data Science & Gen AI Enthusiast

ğŸ“« Connect with me on [LinkedIn](https://www.linkedin.com/in/muqadasejaz/)  

ğŸŒ GitHub: [github.com/muqadasejaz](https://github.com/muqadasejaz)

ğŸ“¬ Kaggle: [Kaggle Profile](https://www.kaggle.com/muqaddasejaz) 

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

## ğŸ“ License

This project is open-source and available under the [MIT License](LICENSE).
